<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>小茗同志 - 流水不腐，户枢不蠹，动也。</title><meta name="author" content="小茗"><meta name="copyright" content="小茗"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="小茗同志">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="小茗同志">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpeg">
<meta property="article:author" content="小茗">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpeg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '小茗同志',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-06-18 02:26:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://fastly.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/index.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">小茗同志</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">小茗同志</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/themoongodyue" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:yuecao04@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2023/03/23/%E5%8F%AF%E6%8E%A7%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E5%B0%8F%E7%BB%BC%E8%BF%B0/" title="可控图像生成小综述"><img class="post_bg" src="https://cdn.pixabay.com/photo/2020/04/03/06/35/work-4997565_960_720.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="可控图像生成小综述"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/23/%E5%8F%AF%E6%8E%A7%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E5%B0%8F%E7%BB%BC%E8%BF%B0/" title="可控图像生成小综述">可控图像生成小综述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-23T20:20:06.000Z" title="发表于 2023-03-23 20:20:06">2023-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/">扩散模型</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E5%BE%AE%E8%B0%83/">微调</a></span></div><div class="content">T2I-Adapter
额外条件的处理生成的特征 Fc\mathbf{F}_cFc​：Fc=FAD(C)\mathbf{F}_c=\mathcal{F}_{A D}(\mathbf{C})Fc​=FAD​(C)
Fc\mathbf{F}_cFc​ 与原网络特征分层结合：F^ldmi=Fldmi+F^ci,i∈{1,2,3,4}\hat{\mathbf{F}}_{l d m}^i=\mathbf{F}_{l d m}^i+\hat{\mathbf{F}}_c^i, i \in\{1,2,3,4\}F^ldmi​=Fldmi​+F^ci​,i∈{1,2,3,4}
多个额外特征共同作用：Fc=∑k∈GkωkFADk(Ck)\mathbf{F}_c=\sum_{k \in \mathcal{G}}^k \omega_k \mathcal{F}_{A D}^k\left(\mathbf{C}^k\right)Fc​=∑k∈Gk​ωk​FADk​(Ck)
损失函数：LAD=EZ0,t,Fc,ϵ∼N(0,1)[∥ϵ−ϵθ(Zt,t,τ(y),Fc)∥22]L_{A D}=\mathbb{E}_{\m ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/03/23/LoRA%E6%A6%82%E8%BF%B0/" title="LoRA概述"><img class="post_bg" src="https://picx.zhimg.com/v2-c8503dc33d5705b5d15a7a7573162d48_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LoRA概述"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/23/LoRA%E6%A6%82%E8%BF%B0/" title="LoRA概述">LoRA概述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-23T16:44:53.000Z" title="发表于 2023-03-23 16:44:53">2023-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%BE%AE%E8%B0%83/">微调</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E8%AE%AD%E7%BB%83/">训练</a></span></div><div class="content">前置知识
Intrinsic rank
内在秩是指一个数据集中最重要的线性无关的特征的数量, 它可以被看作是数据集的内在维度的一个度量。内在秩的概念通常用于描述低秩矩阵近似问题, 其中我们希望通过一个低秩矩阵来近似一个高秩矩阵, 以减少存储和计算的开销。
简介
自然语言处理的一个重要范式是在一般领域数据上进行大规模的预训练，并在特定的任务或领域进行微调。随着模型的逐渐加大，重新训练所有模型参数的完全微调变得不太可行。我们提出了低秩优化（Low-Rank Adaptation），即LoRA，它冻结了预训练的模型权重，并将可训练的秩分解矩阵注入到Transformer架构的每一层，大大减少了下游任务的可训练参数的数量。
作者认为预训练学到的模型是被过度参数化的，即模型中有对当前任务冗余的信息，模型的参数矩阵有较低的&quot;内在秩&quot;。我们假设模型优化过程中权重的变化(即梯度)也具有较低的 “内在秩”，从而导致作者提出的低秩优化（LoRA）方法。LoRA允许在保持预训练的权重冻结的情况下，通过优化密集层(比如注意力模块)的变化的秩分解矩阵来间接地训练神经网络中的一些密集层。
结构 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/03/22/ControlNet/" title="ControlNet"><img class="post_bg" src="https://cdn.pixabay.com/photo/2020/04/03/06/35/work-4997565_960_720.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ControlNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/22/ControlNet/" title="ControlNet">ControlNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-03-22T20:02:19.000Z" title="发表于 2023-03-22 20:02:19">2023-03-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/">扩散模型</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/stablediffusion/">stablediffusion</a></span></div><div class="content">基本概念
AIGC
AIGC即AI Generated Content，是指利用人工智能技术来生成内容，AIGC也被认为是继UGC、PGC之后的新型内容生产方式，AI绘画、AI写作等都属于AIGC的分支。对AIGC来说，2022年被认为是其发展速度惊人的一年。
基本思路
生成过程可控。
原理概要
ControlNet的原理
本质
是给预训练扩散模型增加一个额外的输入，控制它生成的细节。
ControlNet整体思路和架构分工：

作者给出的8种输入分类

草图
边缘图像
语义分割图像
人体关键点特征
霍夫变换检测直线
深度图
人体骨骼
其它

具体思路

先复制一遍扩散模型的权重 得到一个“可训练副本”（trainable copy）；
锁定模型”和“可训练副本”通过一个1×1的卷积层连接，名叫“0卷积层” 0卷积层的权重和偏置初始化为0，这样在训练时速度会非常快，接近微调扩散模型的速度，甚至在个人设备上训练也可以。

作者的工作
作者基于当前大火的Stable Diffusion进行了具体实现，主要架构如下：

</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/02/23/CLIP%E5%9B%BE%E5%83%8F%E6%96%87%E6%9C%AC%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" title="CLIP图像文本对比学习"><img class="post_bg" src="https://cdn.openai.com/research-covers/clip/2x-no-mark.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CLIP图像文本对比学习"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/02/23/CLIP%E5%9B%BE%E5%83%8F%E6%96%87%E6%9C%AC%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" title="CLIP图像文本对比学习">CLIP图像文本对比学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-02-23T17:19:55.000Z" title="发表于 2023-02-23 17:19:55">2023-02-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">自监督学习</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/CLIP/">CLIP</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/">多模态</a></span></div><div class="content">简介
CLIP 是OpenAI 在2021年初的一篇工作：Learning Transferable Visual Models From Natural Language Supervision 。它是一个 zero-shot 的视觉分类模型，预训练的模型在没有微调的情况下在下游任务上取得了很好的迁移效果。作者在30多个数据集上做了测试，涵盖了 OCR、视频中的动作检测、坐标定位等任务。
在引言的最后一段，作者特意强调了 CLIP 的效果：没有在 ImageNet 上做微调的CLIP，竟然能和已经在 ImageNet 上训练好的 Resnet 50 打成平手，简直不可思议。CLIP 为什么能取得如此好的效果？它又有哪些不足之处？CLIP 论文逐段精读【论文精读】 这个视频里朱神带给你答案。
预训练阶段
论文标题中有一个重要的点——自然语言监督。这说明 CLIP 是涉及文字和图片的多模态领域的工作，它从文本中得到监督信号，引导视觉分类的任务。
其实，预训练网络的输入是文字与图片的配对，每一张图片都配有一小句解释性的文字。将文字和图片分别通过一个编码器，得到向量表示。这里的文本编码器就是 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/02/21/DALL-E2%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/" title="DALL-E2及相关技术"><img class="post_bg" src="https://s2.loli.net/2023/02/23/6RaAp9SQxgY7htm.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DALL-E2及相关技术"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/02/21/DALL-E2%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/" title="DALL-E2及相关技术">DALL-E2及相关技术</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-02-21T12:05:39.000Z" title="发表于 2023-02-21 12:05:39">2023-02-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CLIP/">CLIP</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/">多模态</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/">扩散模型</a></span></div><div class="content">1.标题解读
Hierarchical Text-Conditional Image Generation with CLIP Latents
是一种层级式的基于CLIP特征的根据文本生成图像模型。
层级式的意思是说在图像生成时，先生成64*64再生成256*256，最终生成令人叹为观止的1024*1024的高清大图。
DALLE·2模型根据CLIP的文本特征和图像特征最终生成图像，可以看做CLIP的反向过程，因此DALLE·2被作者称为unCLIP
2.前言
022Open AI提出DALLE2， 根据文本描述生成原创性的、现实的图像。可结合概念，属性和风格。
除了根据文本直接生成图片，还可以根据文本对图片进行修改。光线，纹理等。


图一中，在位置3加入火烈鸟，我们甚至可以看到在水中出现了火烈鸟的倒影，这是符合自然规律的。图二中，在水池中添加火烈鸟，出现的是一个火烈鸟的游泳圈，这说明游泳圈与水池的匹配程度较高，这也是符合常识的。以上两个例子真的让人叹为观止，说明了AI的的确确学到了一种很好的数据分布。
我们一直认为AI是能先处理重复性的工作，也就是体力工作。而这种创造性的工作往往是 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/02/17/stable-diffison%E7%9A%84%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90/" title="stable_diffison的结构解析"><img class="post_bg" src="https://s2.loli.net/2023/02/17/C52SmsU1fQlwtTY.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="stable_diffison的结构解析"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/02/17/stable-diffison%E7%9A%84%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90/" title="stable_diffison的结构解析">stable_diffison的结构解析</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-02-17T11:51:50.000Z" title="发表于 2023-02-17 11:51:50">2023-02-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CLIP/">CLIP</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/">扩散模型</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/stablediffusion/">stablediffusion</a></span></div><div class="content">曹越 201901061303 毕设周记2

Stable Diffision 概览

模型架构
sd主要由三个部分组成：VAE，CLIP或其他语言模型，UNet或其他图像预测模型

VAE：预训练的变分自编码器，在预处理阶段将训练集图片用VAE编码器编码成特征，将编码后的图片喂给模型；在训练完预测式的后处理阶段，将模型生成的特征用VAE解码器解析成图像
CLIP或其他语言模型：大多为预训练的模型，将prompt编码，用来在逆向扩散时给unet提供指导，具体怎么做请看博主有关dall-e 2的文章
UNet或其他图像预测模型：扩散模型的主体部分，需要也是原始sd唯一需要训练的模块，用来在逆向过程中预测噪声，详情请看博主的这篇文章:diffusion_model

各种微调方法
主要分为两个大类：训练微调、模型融合
具体操作方法等下再写

训练微调
微调text encoder(CLIP)

embedding：

text inversion：比如将一组图片训练编码成文本特征，并将该特征对应成一个或几个prompt，可以学习画风，人物等。（还不太明白，待完善）


finetune：同 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/02/09/DETR%E8%AF%A6%E8%A7%A3/" title="DETR详解"><img class="post_bg" src="/image/dert/640(1).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DETR详解"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/02/09/DETR%E8%AF%A6%E8%A7%A3/" title="DETR详解">DETR详解</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-02-09T21:38:24.000Z" title="发表于 2023-02-09 21:38:24">2023-02-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span></div><div class="content">DETR简介
目标检测算法，pipeline太复杂？不同任务人工设计不同的非极大值抑制(NMS)阈值、生成新的锚点(Anchor)？是不是直接戳中了各位开发者的痛点！莫慌，今天小编就为万千开发者破局~这个破局点就是：基于transform的目标检测算法DETR，简洁的pipeline，去除NMS、Anchor设计，且在COCO数据集上的指标与Faster RCNN相当。
本项目将为大家详细介绍DETR算法。同时，将带领大家使用飞桨2.1版本在COCO数据集上实现基于DETR模型的目标检测，以及使用训练好的模型进行评估和预测。DETR检测效果如图1所示：

看可以看出DETR将上图中的目标(人、包、椅子等)基本都可以正确检测出来，效果还是不错的~
而这个DETR到底是如何设计，从而有这么好的性能的呢？下面小编就带大家来领略一下：

DETR模型结构
整体结构
DETR即Detection Transformer，是Facebook AI 的研究者提出的 Transformer 的视觉版本，可以用于目标检测，也可以用于全景分割。这是第一个将 Transformer成功整合为检测pipeli ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/02/09/MoCo-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E8%AF%A6%E8%A7%A3/" title="moco对比学习详解"><img class="post_bg" src="https://img-blog.csdnimg.cn/7269e2cdab684831addc64b4f045cdaf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zm25bCG,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="moco对比学习详解"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/02/09/MoCo-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E8%AF%A6%E8%A7%A3/" title="moco对比学习详解">moco对比学习详解</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-02-09T21:38:24.000Z" title="发表于 2023-02-09 21:38:24">2023-02-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">自监督学习</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/MoCo/">MoCo</a></span></div><div class="content">MoCo是视觉对比学习(自监督学习)的优秀论文</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/01/16/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%8E%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BB%93%E5%90%88%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" title="mindspore面向对象与函数式结合的神经网络编程"><img class="post_bg" src="https://cdn.pixabay.com/photo/2020/04/03/06/35/work-4997565_960_720.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mindspore面向对象与函数式结合的神经网络编程"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/01/16/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%8E%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BB%93%E5%90%88%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" title="mindspore面向对象与函数式结合的神经网络编程">mindspore面向对象与函数式结合的神经网络编程</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-01-16T17:10:58.000Z" title="发表于 2023-01-16 17:10:58">2023-01-16</time></span></div><div class="content"></div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/01/12/Vision-Transformer/" title="Vision Transformer"><img class="post_bg" src="/image/transformer/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Vision Transformer"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/01/12/Vision-Transformer/" title="Vision Transformer">Vision Transformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-01-12T21:01:11.000Z" title="发表于 2023-01-12 21:01:11">2023-01-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span></div><div class="content">CV-transformer的相关工作
使用CNN处理后特征图作为transformer的输入，来减少复杂度
孤立自注意力（在一个限定的框内做注意力），轴自注意力（把图片的没一行或者每一列看成一个向量；行于行，列与列之间做注意力）
简介
其模型“简单”且效果好，可扩展性强 （scalable，模型越大效果越好），打破了CV与NLP之间的隔阂，成为了transformer在CV领域、多模态领域应用的里程碑著作，也引爆了后续相关研究。
但由于其缺少一些 **归纳偏执（inductive bias）**即一种先验知识，提前做好的假设，会导致其在小规模数据集上表现不佳。CV上的归纳偏执有 局部性，即图片上相邻的区域具有相似的特征；平移不变形，即卷积和平移的操作顺序可交换。当CNN具有以上两种归纳偏置，就有了很多先验信息，需要相对少的数据就可以学习一个比较好的模型
ViT的整体流程

本例图片大小为224*224
图片预处理


patch embedding: 将图片分为固定大小的patch，patch大小为16x16，则每张图像会生成(224x224)/(16x16)=196个patch，即 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">小茗</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/themoongodyue"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/themoongodyue" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:yuecao04@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/06/18/hello-world/" title="Hello World"><img src="https://cdn.pixabay.com/photo/2020/04/03/06/35/work-4997565_960_720.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2025/06/18/hello-world/" title="Hello World">Hello World</a><time datetime="2025-06-18T02:26:21.663Z" title="发表于 2025-06-18 02:26:21">2025-06-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/20/think-of-GNN/" title="think of GNN"><img src="https://s21.ax1x.com/2025/02/20/pEQwN5V.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="think of GNN"/></a><div class="content"><a class="title" href="/2025/02/20/think-of-GNN/" title="think of GNN">think of GNN</a><time datetime="2025-02-20T16:27:34.000Z" title="发表于 2025-02-20 16:27:34">2025-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/20/Code-of-GNN/" title="Code of GNN"><img src="https://s21.ax1x.com/2025/02/20/pEQn8xS.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Code of GNN"/></a><div class="content"><a class="title" href="/2025/02/20/Code-of-GNN/" title="Code of GNN">Code of GNN</a><time datetime="2025-02-20T08:38:08.000Z" title="发表于 2025-02-20 08:38:08">2025-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/07/test/" title="test"><img src="https://cdn.pixabay.com/photo/2020/04/03/06/35/work-4997565_960_720.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="test"/></a><div class="content"><a class="title" href="/2024/07/07/test/" title="test">test</a><time datetime="2024-07-07T12:21:56.000Z" title="发表于 2024-07-07 12:21:56">2024-07-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/20/Triton-Inference-Server/" title="Triton Inference Server"><img src="https://s2.loli.net/2024/05/20/GzBTujbQtSUwdC8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Triton Inference Server"/></a><div class="content"><a class="title" href="/2024/05/20/Triton-Inference-Server/" title="Triton Inference Server">Triton Inference Server</a><time datetime="2024-05-20T10:47:07.000Z" title="发表于 2024-05-20 10:47:07">2024-05-20</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/CMake/"><span class="card-category-list-name">CMake</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BB%A3%E7%A0%81/"><span class="card-category-list-name">代码</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%9B%BD%E9%99%85%E4%B8%BB%E4%B9%89/"><span class="card-category-list-name">国际主义</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">11</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83/"><span class="card-category-list-name">系统环境</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87/"><span class="card-category-list-name">论文</span><span class="card-category-list-count">1</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/C-C/" style="font-size: 1.23em; color: #999ea6">C/C++</a> <a href="/tags/CLIP/" style="font-size: 1.37em; color: #99a4b2">CLIP</a> <a href="/tags/CMake/" style="font-size: 1.23em; color: #999ea6">CMake</a> <a href="/tags/GNN/" style="font-size: 1.37em; color: #99a4b2">GNN</a> <a href="/tags/MoCo/" style="font-size: 1.1em; color: #999">MoCo</a> <a href="/tags/Transformer/" style="font-size: 1.23em; color: #999ea6">Transformer</a> <a href="/tags/VSCode/" style="font-size: 1.1em; color: #999">VSCode</a> <a href="/tags/blogs/" style="font-size: 1.1em; color: #999">blogs</a> <a href="/tags/linux/" style="font-size: 1.1em; color: #999">linux</a> <a href="/tags/stablediffusion/" style="font-size: 1.23em; color: #999ea6">stablediffusion</a> <a href="/tags/%E4%BB%A3%E7%A0%81/" style="font-size: 1.1em; color: #999">代码</a> <a href="/tags/%E5%85%A5%E9%97%A8/" style="font-size: 1.1em; color: #999">入门</a> <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 1.37em; color: #99a4b2">图神经网络</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 1.23em; color: #999ea6">多模态</a> <a href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" style="font-size: 1.23em; color: #999ea6">对比学习</a> <a href="/tags/%E5%B7%B4%E4%BB%A5/" style="font-size: 1.1em; color: #999">巴以</a> <a href="/tags/%E5%BE%AE%E8%B0%83/" style="font-size: 1.23em; color: #999ea6">微调</a> <a href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" style="font-size: 1.5em; color: #99a9bf">扩散模型</a> <a href="/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 1.23em; color: #999ea6">自监督学习</a> <a href="/tags/%E8%AE%AD%E7%BB%83/" style="font-size: 1.1em; color: #999">训练</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 1.1em; color: #999">论文</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/02/"><span class="card-archive-list-date">二月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/12/"><span class="card-archive-list-date">十二月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">三月 2023</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">24</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2020-06-07T00:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-06-18T02:26:40.778Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 小茗</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["流水不腐，户枢不蠹，动也。"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '流水不腐，户枢不蠹，动也。'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>